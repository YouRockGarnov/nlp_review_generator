{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of baseline INF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBVr84s-Jbjq",
        "colab_type": "text"
      },
      "source": [
        "В данном ноутбуке я смотрю на отзывы, сгерерированные моделью gpt-2 \"117M\" (это предтренированная модель с 117 миллионами параметров, которая дообучается на нашем датасете)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SD2zRyKKImb",
        "colab_type": "text"
      },
      "source": [
        "! Данный ноутбук нужно запускать из Google Colab !\n",
        "Пометка для себя - я это делал под аккаунтом garnov.yud@phystech.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq_L3J3UJ6fC",
        "colab_type": "text"
      },
      "source": [
        "Импортируем нужные модули, gpt-2 работает с tensorflow первой версии."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hdr-6u0O4ck",
        "colab_type": "code",
        "outputId": "c7ff678f-8f08-4a98-d952-ed4556d075d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6QMw_C-KC_D",
        "colab_type": "text"
      },
      "source": [
        "Проверяем, что сейчас мы используем GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v4VHq5yCCL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import bz2\n",
        "import gc\n",
        "import chardet\n",
        "import re\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "delim = '==============================================='"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk_LV6U3Kc6Y",
        "colab_type": "text"
      },
      "source": [
        "Чтобы не потерять прогресс, добавим Google Drive как хранилище, чтобы gpt2 могло складывать туда результаты и модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77-jIlbuINO0",
        "colab_type": "code",
        "outputId": "b39980b4-c188-44a3-b450-b79b245e7e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9PPYaAjKo4y",
        "colab_type": "text"
      },
      "source": [
        "Загружаем модель. Я использовал самую малую \"117М\", потому что обучение на других занимает очень много времени и Google Colab нередко падает из-за нехватки RAM. Для более точных результатов советую взять версию побольше (см. тут https://github.com/openai/gpt-2/issues/209)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLjM-tVa9e8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_name = \"117M\"\n",
        "# if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "# \tprint(f\"Downloading {model_name} model...\")\n",
        "# \t# gpt2.download_gpt2(model_dir=root_path + '/models', model_name=model_name)   # model is saved into current directory under /models/774M/\n",
        "# \tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/774M/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otPt9YW8LCE_",
        "colab_type": "text"
      },
      "source": [
        "Начинаем сессию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWxBRDtmH7wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gc.collect()\n",
        "gpt2.copy_checkpoint_from_gdrive()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4fguE_YT7uF",
        "colab_type": "code",
        "outputId": "af02c9f7-7a23-4ad4-d701-1144befbeb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBQ7I5qRL418",
        "colab_type": "text"
      },
      "source": [
        "Попробуем поиграться с разными параметрами генерирования текстов, например длиной."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfff7xj9L-6K",
        "colab_type": "code",
        "outputId": "ccf2e9aa-0f96-4ce2-902e-7e137391ed55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "for length in [le for le in range(10, 65, 10)]:\n",
        "  print(delim + str(length) + delim)\n",
        "  gpt2.generate(sess, length=length)\n",
        "  print('\\n')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================10===============================================\n",
            "great movie for the price so don't be fooled\n",
            "\n",
            "\n",
            "===============================================20===============================================\n",
            "\"i am so sorry\" lyrics - even my favorite song is still right there. this album is\n",
            "\n",
            "\n",
            "===============================================30===============================================\n",
            "i was really disappointed in this movie. the movie was a waste of time and i was forced to watch it over and over. i felt like i\n",
            "\n",
            "\n",
            "===============================================40===============================================\n",
            "\"a little boy is about to be born\". it is a boy named julie who is very happy and happy, but when he is about to be born, he is sent to a school\n",
            "\n",
            "\n",
            "===============================================50===============================================\n",
            "if you are looking for an easy way to set up an internet router, broadband, or any other router for use on a home network, this is the router.it is a little big and fits snugly on the router and yet the internet is\n",
            "\n",
            "\n",
            "===============================================60===============================================\n",
            "michael m. jones is a very talented writer and director. he has the unique ability to create a film that is much more engaging than the previous dvd release. a very exciting and exciting film. this, the first movie in the series, is a must see.\n",
            "great. wasted\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iduaf3Q4WChR",
        "colab_type": "text"
      },
      "source": [
        "Как мы видим для каждой длины модель генерирует человекоподобные отзывы. Однако есть ощущение, что они какие-то незаконченные. Можем дать модели возможность самой определять когда ей нужно остановиться и обрезать отзывы по \\n. Так же можно задать с чего модели начать отзыв, то есть можно генерировать отзывы о конкретной вещи. Давайте попробуем дать ей тему для отзыва."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DiredvqWBhr",
        "colab_type": "code",
        "outputId": "dd823cc4-5496-4a95-baee-3490ddab4317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "topics = ['The book', 'This film', 'The album', 'The phone']\n",
        "\n",
        "for topic in topics:\n",
        "    print(delim + str(topic) + delim)\n",
        "    gpt2.generate(sess, prefix=topic, truncate='\\n', length=50)\n",
        "    print('\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================The book===============================================\n",
            "The book was enjoyable but didn't keep me reading. i hope you enjoy it.\n",
            "\n",
            "\n",
            "===============================================This film===============================================\n",
            "This film is very, very well made. it is an intriguing story, but it takes a while to get to the point. i would not recommend this to anyone.\n",
            "\n",
            "\n",
            "===============================================The album===============================================\n",
            "The album basically is a collection of songs that were released in the 0000s, and they have been given a new life over the years. the songwriting is just plain cool, and the lyrics are all very catchy. the only problem is that the songwriting\n",
            "\n",
            "\n",
            "===============================================The phone===============================================\n",
            "The phone is the perfect device for a home phone. it has a good volume. i have a full-size phone and the older one is 00/0x better. it is now my only phone.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ku55rloiyOM",
        "colab_type": "text"
      },
      "source": [
        "Удивительно, но модель даже довольно хорошо справляется с названиями продуктов, не только с конкретной категорией."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXjXcP_fh14G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61baefa3-0088-4369-b52a-fcb3782e9e6d"
      },
      "source": [
        "name = 'Samsung Galaxy S8 '\n",
        "gpt2.generate(sess, prefix=name, truncate='\\n', length=80, include_prefix=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samsung Galaxy S8 is iced, by far the worst. to get it you have to buy it from a website or buy the product from a store. it has a video buffering problem, very annoying, in my opinion. the price is right, and the customer service is a mess. i will not buy this again.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smloOBM9jMzn",
        "colab_type": "text"
      },
      "source": [
        "Однако если дать модели название товара абсолютно такое же как и в Amazon, то модель будет удивлена и не поймёт что мы от неё хотим, так как названия у товаров обычно содержат очень много технических характеристик, которые не особо много информации дают для отзыва. Точнее это слишком сложный контекст для модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPPR4E23jAYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9854ff27-0e8e-4328-e196-f8f6ae191468"
      },
      "source": [
        "sg_tab = 'Samsung Galaxy Tab A 10.1 Inch (T510) 32 GB WiFi Tablet Silver (2019), Silver'\n",
        "gpt2.generate(sess, prefix=sg_tab, truncate='\\n', length=50, include_prefix=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samsung Galaxy Tab A 10.1 Inch (T510) 32 GB WiFi Tablet Silver (2019), Silver (0000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQzvchwjN6_x",
        "colab_type": "text"
      },
      "source": [
        "О параметре top_k сами разработчики отзываются следующим образом: \n",
        "\n",
        "`\n",
        "top_k=0: Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 is a special setting meaning no restrictions. 40 generally is a good value.\n",
        "`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6q9oIpYL_Zm",
        "colab_type": "code",
        "outputId": "9a424256-f935-4124-8add-ff1fd5b89f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "def generate_samples(session, kwarg_name, kwarg_list: list, **kwargs):\n",
        "    for kwarg in kwarg_list:\n",
        "        print(delim + str(kwarg) + delim)\n",
        "        gpt2.generate(session, length=50, **{kwarg_name: kwarg}, truncate='\\n', **kwargs)\n",
        "        print('\\n')\n",
        "\n",
        "ks = [20, 40, 60]\n",
        "generate_samples(sess, 'top_k', ks)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================20===============================================\n",
            "\"a man who cannot live\" is the book that will forever define the genre of the 00th century. the authors have made one hell of a world of literature. they are a great author, but they are also a great writer. they should\n",
            "\n",
            "\n",
            "===============================================40===============================================\n",
            "great fun, good read, it's a great book!\n",
            "\n",
            "\n",
            "===============================================60===============================================\n",
            "as the other reviewer stated, the black box was not included in the purchase price. it was too small and the box was too small. i was able to keep it for 0 hours and finally received the box. it is not worth the price.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ulC6oPjOW4v",
        "colab_type": "text"
      },
      "source": [
        "Параметр temperature означает следующее:\n",
        "\n",
        "`:temperature=1: Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions.`\n",
        "\n",
        "То есть, для отзывов непохожих на отзывы из датасета нужно выбрать температуру как можно ближе к 1. Для похожих наоборот."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-COMgsKMA1g",
        "colab_type": "code",
        "outputId": "2b8e6ac6-863c-41dd-ff26-71349b87e703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "temps = [0.1, 0.4, 1.0]\n",
        "generate_samples(sess, 'temperature', temps, top_k=40)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===============================================0.1===============================================\n",
            "\"the best of the best\" is a great book. i read it in the middle of the night, and i was hooked. i have read it many times, and i still love it. i have read it many times, and i still\n",
            "\n",
            "\n",
            "===============================================0.4===============================================\n",
            "\"the world of the kiddies\" is a very good movie, but it's not a \"movie\" either. it's a \"movie\" with a lot of action, and a lot of nudity. it's not a \"movie\"\n",
            "\n",
            "\n",
            "===============================================1.0===============================================\n",
            "toilet humor with a flair for the outrageous. don't waste your money!\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piuSf54Rjtqg",
        "colab_type": "text"
      },
      "source": [
        "Заключение: gpt-2 несмотря на то, что я обучил модель не полном датасете и взял самую маленькую версию модели из-за нехватки ресурсов, прекрасно справляется с генерированием различного рода текстов, в частности отзывов. Отзывы выглядят очень человечными и складными. Кроме того, данную модель можно ещё несколько раз дообучать на выборке, чтобы снизить loss, что ещё улучшит качество генерирования текстов."
      ]
    }
  ]
}